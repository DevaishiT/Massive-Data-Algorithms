{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StreamingAlgo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5DD_V2cASGw"
      },
      "source": [
        "# GENERATING THE DATA STREAM "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZpABxYHi-hS",
        "outputId": "f200331d-c220-418f-8acd-b9723b89a289"
      },
      "source": [
        "# Generating random datasets \n",
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "data = np.random.randint(1,25,100)\n",
        "with open('data.csv', mode='w') as dataset:\n",
        "    data_writer = csv.writer(dataset, delimiter=',')\n",
        "    data_writer.writerow(data)\n",
        "\n",
        "print(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 9 17 24  2 15  1  2  4 15  5 24  4 21  7 18 15 21  9 23  4 20 21 23  5\n",
            "  1 19 13  5 11 18  3 22 19  8 13 17  1 14 22 14  8  1 22  6 10 22 23 18\n",
            "  7  3  8 21 20 24 19  9 15 17 22  6  8  3 13  1  8 16 23 10  9 24 18  4\n",
            "  3 22 15  8  6  3  3  1 24 22 16 20 18 19 16 17 11  9 20 22  1  8 19  4\n",
            "  8 23 24  4]\n",
            "{9: 5, 17: 4, 24: 6, 2: 2, 15: 5, 1: 7, 4: 6, 5: 3, 21: 4, 7: 2, 18: 5, 23: 5, 20: 4, 19: 5, 13: 3, 11: 2, 3: 6, 22: 8, 8: 8, 14: 2, 6: 3, 10: 2, 16: 3}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlugqdNkAY6g"
      },
      "source": [
        "## Getting the tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUqVr5YNGX4p",
        "outputId": "a21d9a38-81be-49fc-eb6c-98c1d9048139"
      },
      "source": [
        "# Installing the tweepy function to utilize Twitter API\n",
        "!pip install tweepy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.7/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA0TurPzPUEY"
      },
      "source": [
        "import tweepy\n",
        "\n",
        "# Creating a file to store all the trending Hashtags\n",
        "file1 = open('data.txt', mode='w')\n",
        "\n",
        "# Specify all the tokens, keys and secrets to authenticate\n",
        "consumer_key = \"xxxxxxxxxxxxxxxxxxxxxxx\"\n",
        "consumer_secret = \"xxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
        "access_token = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
        "access_token_secret = \"xxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
        "\n",
        "# Creating the authentication object\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "\n",
        "# Setting your access token and secret\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "\n",
        "# Creating the API object while passing in auth information\n",
        "api = tweepy.API(auth) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkBnz53TAuLJ"
      },
      "source": [
        "## Collecting the hashtags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55b5a13-PvwU"
      },
      "source": [
        "query = \"Trending\"\n",
        "language = \"en\"\n",
        "\n",
        "# Calling the api.search function with our parameters\n",
        "results = api.search(q=query, lang=language, count=100)\n",
        "\n",
        "# Iterating through all the tweets to collect hashtags\n",
        "for tweet in results :\n",
        "  # print(tweet.entities[\"hashtags\"])\n",
        "  for tag in tweet.entities[\"hashtags\"] :\n",
        "    # print(tag[\"text\"])\n",
        "    file1.write(tag[\"text\"] + \",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoEfvPp_bCwI"
      },
      "source": [
        "file1.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyBBI7kIDOsV"
      },
      "source": [
        "Note: We are using this data.txt file as our data stream for the sake of simplicity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3X6hs86A389"
      },
      "source": [
        "# DISTINCT ELEMENTS COUNT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDqLW7HUczR_"
      },
      "source": [
        "## Actual distinct count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "TehfFFpkc4Mc",
        "outputId": "1216d5d5-afdf-4169-ba1a-c20f43918a58"
      },
      "source": [
        "file1 = open('alllines.txt', mode='r')\n",
        "\n",
        "# Maintaining an array of distinct tags\n",
        "tags_set = []\n",
        "for line in file1 : \n",
        "  hashtag_data = line.split(',')\n",
        "  for tag in hashtag_data :\n",
        "    if tag not in tags_set:\n",
        "      tags_set.append(tag)\n",
        "\n",
        "# print(tags_set)\n",
        "print(len(tags_set))\n",
        "\n",
        "file1.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c8364d2428d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mhashtag_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhashtag_data\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtags_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m       \u001b[0mtags_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uR2x0vPXcvHZ"
      },
      "source": [
        "## Flajolet Martin Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1HKlgjiLFoQ",
        "outputId": "9bbdccdc-5d99-444b-a59f-dcb21b45522a"
      },
      "source": [
        "# Installing packages to use multiple hash functions\n",
        "!pip3 install mmh3\n",
        "import mmh3\n",
        "\n",
        "!pip install xxhash\n",
        "import xxhash\n",
        "\n",
        "!pip install spooky\n",
        "from spooky import hash32\n",
        "\n",
        "!pip install jhashcode\n",
        "import jhashcode\n",
        "\n",
        "# Importing essential packages\n",
        "import statistics\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mmh3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/46/0e568554c7f70ebc3de0c2b2effd3f7b25e66e0e4e0eacaeb7c9145949f2/mmh3-3.0.0-cp37-cp37m-manylinux2010_x86_64.whl (50kB)\n",
            "\r\u001b[K     |██████▍                         | 10kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 20kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 30kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 40kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 1.9MB/s \n",
            "\u001b[?25hInstalling collected packages: mmh3\n",
            "Successfully installed mmh3-3.0.0\n",
            "Collecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/4f/0a862cad26aa2ed7a7cd87178cbbfa824fc1383e472d63596a0d018374e7/xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 2.6MB/s \n",
            "\u001b[?25hInstalling collected packages: xxhash\n",
            "Successfully installed xxhash-2.0.2\n",
            "Collecting spooky\n",
            "  Downloading https://files.pythonhosted.org/packages/c5/1c/56e3589d67e25b76bdc8937585fd4112c9d4a04eff120723111631c5ca36/spooky-2.0.0.tar.gz\n",
            "Building wheels for collected packages: spooky\n",
            "  Building wheel for spooky (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spooky: filename=spooky-2.0.0-cp37-cp37m-linux_x86_64.whl size=36468 sha256=1e0b1a2afe009897936975f1d64cfe12868088804ab260be2d103a4a0f9a8bed\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/2f/73/4d170f5f35ae79510b846c6db6ca0202f6f4e9e4ea21b2809c\n",
            "Successfully built spooky\n",
            "Installing collected packages: spooky\n",
            "Successfully installed spooky-2.0.0\n",
            "Collecting jhashcode\n",
            "  Downloading https://files.pythonhosted.org/packages/42/41/2339187ffcf3019c655da103f987e5aa4eedffdc674378a1b2d88a12d54a/jhashcode-0.4.tar.gz\n",
            "Building wheels for collected packages: jhashcode\n",
            "  Building wheel for jhashcode (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jhashcode: filename=jhashcode-0.4-cp37-none-any.whl size=2577 sha256=99ef94f64d33278746de476745e276b9133535900fd54ee719176130de0026fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/fb/41/f8b536c775410bd617340b8cc3b87561e4266242354dd3ecbb\n",
            "Successfully built jhashcode\n",
            "Installing collected packages: jhashcode\n",
            "Successfully installed jhashcode-0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_5YdZxPNwmC"
      },
      "source": [
        "# Returning the number of trailing zeroes in a binary representation\n",
        "def tail_len (binary) :\n",
        "  binary_str = str(binary)\n",
        "  binary_str_rev = binary_str[::-1]\n",
        "\n",
        "  # Iterating through the string\n",
        "  count = 0\n",
        "  for i in binary_str_rev :\n",
        "    if i is '0':\n",
        "      count = count + 1\n",
        "    else:\n",
        "      break\t\t\n",
        "\n",
        "  # In case the binary representation is 000...00, the trailing zeroes should be 0\n",
        "  if count == 32 :\n",
        "    return 0\n",
        "  else :\n",
        "    return count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7NLEjxGBF2W"
      },
      "source": [
        "file2 = open('alllines.txt', mode='r')\n",
        "\n",
        "# Creating files to store the hashed values of tags\n",
        "hash_file1 = open('hash_function1.txt', mode = 'w')\n",
        "hash_file2 = open('hash_function2.txt', mode = 'w')\n",
        "hash_file3 = open('hash_function3.txt', mode = 'w')\n",
        "hash_file4 = open('hash_function4.txt', mode = 'w')\n",
        "\n",
        "# Hashing the tags and storing trailing zero count of their binary representations\n",
        "for line in file2 : \n",
        "  hashtag_data = line.split(',')\n",
        "  for tag in hashtag_data :\n",
        "    value1 = format(abs(mmh3.hash(tag)), '032b')\n",
        "    value2 = format(abs(xxhash.xxh32(tag).intdigest()), '032b')\n",
        "    value3 = format(abs(hash32(tag)), '032b')\n",
        "    value4 = format(abs(jhashcode.hashcode(tag)), '032b')\n",
        "\n",
        "    hash_file1.write(str(tail_len(value1)) + \"\\n\")\n",
        "    hash_file2.write(str(tail_len(value2)) + \"\\n\")\n",
        "    hash_file3.write(str(tail_len(value3)) + \"\\n\")\n",
        "    hash_file4.write(str(tail_len(value4)) + \"\\n\")\n",
        "\n",
        "file2.close()\n",
        "hash_file1.close()\n",
        "hash_file2.close()\n",
        "hash_file3.close()\n",
        "hash_file4.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QXiELgPewlj",
        "outputId": "749156d5-f16f-4392-e137-9b7b9f38e704"
      },
      "source": [
        "# Finding maximum hashed value in each case\n",
        "hash_max1 = 0\n",
        "with open('hash_function1.txt', mode='r') as file1:\n",
        "  for value in file1:\n",
        "      if int(value.rstrip('\\n')) > hash_max1:\n",
        "          hash_max1 = int(value.rstrip('\\n'))\n",
        "file1.close()\n",
        "\n",
        "hash_max2 = 0\n",
        "with open('hash_function2.txt', mode='r') as file2:\n",
        "  for value in file2:\n",
        "      if int(value.rstrip('\\n')) > hash_max2:\n",
        "          hash_max2 = int(value.rstrip('\\n'))\n",
        "file2.close()\n",
        "\n",
        "hash_max3 = 0\n",
        "with open('hash_function3.txt', mode='r') as file3:\n",
        "  for value in file3:\n",
        "      if int(value.rstrip('\\n')) > hash_max3:\n",
        "          hash_max3 = int(value.rstrip('\\n'))\n",
        "file3.close()\n",
        "\n",
        "hash_max4 = 0\n",
        "with open('hash_function4.txt', mode='r') as file4:\n",
        "  for value in file4:\n",
        "      if int(value.rstrip('\\n')) > hash_max4:\n",
        "          hash_max4 = int(value.rstrip('\\n'))\n",
        "file4.close()\n",
        "\n",
        "print (hash_max1)\n",
        "print (hash_max2)\n",
        "print (hash_max3)\n",
        "print (hash_max4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "6\n",
            "6\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkB6h1MucEO2",
        "outputId": "c7445f3c-b60c-41d4-bf88-b57f9eb9a6c8"
      },
      "source": [
        "# Approximating the distinct count\n",
        "phi = 0.77351\n",
        "average12 = (2**hash_max1/phi + 2**hash_max2/phi)/2.0\n",
        "average34 = (2**hash_max3/phi + 2**hash_max4/phi)/2.0\n",
        "# print (average12, average34)\n",
        "distinct_count = math.ceil(statistics.median([average12, average34]))\n",
        "print (distinct_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "62.0547892076379 124.1095784152758\n",
            "94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4q3BKFAiYjr"
      },
      "source": [
        "# K MOST FREQUENT ELEMENTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIEivmIP3NdQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4df3a998-1a5e-48d1-f288-94f89ec4b611"
      },
      "source": [
        "file1 = open('dataset.txt', mode='r')\n",
        "\n",
        "dictionary = {}\n",
        "for line in file1 : \n",
        "  hashtag_data = line.split(',')\n",
        "  for tag in hashtag_data :\n",
        "    if tag in dictionary :\n",
        "      dictionary[tag] += 1\n",
        "    else :\n",
        "      dictionary[tag] = 1\n",
        "\n",
        "print(dictionary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'GulfKanawut': 11, 'TXT_TheDoomsNight': 36, 'txt': 36, 'Madhanya': 5, 'MadhanyaOutNow': 6, 'POSTPONE_SSC_CHSL': 98, '100DaysLockey': 10, '시크릿넘버': 10, 'ASAPlivenalive': 16, 'Trending': 4, 'India': 1, 'कंप्यूटर_शिक्षक_आईटी_सेल': 3, 'กลัฟขอไปแซ่บใน3แซ่บ': 30, 'JinTrend': 1, 'BANGBANGCON21': 4, 'wHOONderfulSunday': 1, '지훈': 1, '트레저': 1, 'fireforce': 1, 'PantamiResignNow': 1, 'Gulfkanawut': 1, 'cancelallboardexams2021': 1, 'dontpostponeboardexams': 1, 'CancelGSEBboardexam2021': 1, 'CancelAllBoardExams': 1, 'btsvsexo': 1, 'FarmerLivesMatter': 1, 'KomaramBheemNTR': 2, 'woke': 1, 'postponevtuexams': 1, 'cancelvtuexams': 1, 'VTU': 1, 'vtustudents': 1, 'savevtustudents': 1, 'YUNHYEONG': 2, '송윤형': 1, '윤형': 1, 'ユニョン': 1, '宋尹亨': 1, 'iKON': 1, '아이콘\\n': 1, 'แลกฟอลเพื่อบบ': 1, 'ด้อม25': 1, 'seungmin': 1, 'DogeDay420': 1, 'TBADNBoycottMZETxAPT42': 1, 'Valimai': 1, 'Ajithkumar': 1, 'SpreadAJITHism': 1, 'KerajaanGagal': 2, 'actingchallenge': 1, 'hinakhan': 1, 'Hina': 1, 'thebakerandthebeauty': 1, 'MeetSB19onTikTok': 1, 'ChenZhuoxuan': 1, 'TigerHu': 1, 'YouthandMelody': 1, 'Cancel_HSLC_Board_Exam': 1, 'IceAgeWatch': 1, 'RahulVaidya': 1, 'Iran': 1, 'baghdad': 1, 'iraq': 1, 'SB19': 1, 'POSTPONE_SSC_CHSL\\n': 1, 'BGYOConcertVibes': 1, 'LeeKnow': 1, 'MayWard': 1, 'OurFutureWithIZONE': 1, 'FYP': 2, 'subscribe': 2, 'Viral': 2, 'Trends': 2, 'jaeten': 1, 'DARRENisback': 1, 'trending': 1, 'cancelcie2021nepal': 1, 'SarkaruVaariPaata': 1, 'MaheshBabu': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ecUwoHSmO7N"
      },
      "source": [
        "## Actual Frequent Elements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l12L-H73n4mA"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "rank_until = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nZTBW4Iijc4",
        "outputId": "439f7d78-8067-4549-f72b-ed8846ec7b8b"
      },
      "source": [
        "file1 = open('dataset.txt', mode='r')\n",
        "\n",
        "tag_array = []\n",
        "for line in file1 : \n",
        "  hashtag_data = line.split(',')\n",
        "  for tag in hashtag_data :\n",
        "    tag_array.append(tag)\n",
        "\n",
        "tag_count = Counter(tag_array)\n",
        "for rank, value in enumerate(sorted(tag_count, key=tag_count.get, reverse=True)):\n",
        "    rank += 1\n",
        "    if rank > rank_until:\n",
        "        break\n",
        "    print(rank, value, tag_count[value])\n",
        "\n",
        "file1.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 POSTPONE_SSC_CHSL 98\n",
            "2 TXT_TheDoomsNight 36\n",
            "3 txt 36\n",
            "4 กลัฟขอไปแซ่บใน3แซ่บ 30\n",
            "5 ASAPlivenalive 16\n",
            "6 GulfKanawut 11\n",
            "7 100DaysLockey 10\n",
            "8 시크릿넘버 10\n",
            "9 MadhanyaOutNow 6\n",
            "10 Madhanya 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay0EnCfymVKC"
      },
      "source": [
        "## Misra Gries Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndVzqjCkoC6q",
        "outputId": "3e9d2a51-0bde-47b6-f638-529c2f4657a8"
      },
      "source": [
        "file2 = open('dataset.txt', mode='r')\n",
        "\n",
        "count = 0\n",
        "tag_dictionary = {}\n",
        "for line in file2 : \n",
        "  hashtag_data = line.split(',')\n",
        "  for tag in hashtag_data :\n",
        "    if tag in tag_dictionary :\n",
        "      tag_dictionary[tag] += 1\n",
        "      # print (\"app\", tag, count, tag_dictionary[tag])\n",
        "  \n",
        "    elif count < 2*rank_until :\n",
        "      tag_dictionary[tag] = 1\n",
        "      count += 1\n",
        "      # print (\"add\", tag, count, tag_dictionary[tag])\n",
        "\n",
        "    else :\n",
        "      tag_array = list(tag_dictionary.keys())\n",
        "      # print (\"rem\", count)\n",
        "      for key in tag_array :\n",
        "        tag_dictionary[key] -= 1\n",
        "        if tag_dictionary[key] == 0 :\n",
        "          tag_dictionary.pop(key)\n",
        "          count -= 1\n",
        "          \n",
        "      # print (\"rem\", count)\n",
        "\n",
        "for rank, value in enumerate(sorted(tag_dictionary, key=tag_dictionary.get, reverse=True)):\n",
        "    rank += 1\n",
        "    if rank > rank_until:\n",
        "        break\n",
        "    print(rank, value, tag_dictionary[value])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 POSTPONE_SSC_CHSL 91\n",
            "2 TXT_TheDoomsNight 29\n",
            "3 txt 29\n",
            "4 กลัฟขอไปแซ่บใน3แซ่บ 23\n",
            "5 ASAPlivenalive 9\n",
            "6 GulfKanawut 4\n",
            "7 100DaysLockey 3\n",
            "8 시크릿넘버 3\n",
            "9 Madhanya 1\n",
            "10 Viral 1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}